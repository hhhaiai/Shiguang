// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.11.1.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../../frb_generated.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
part 'tensorrt.freezed.dart';

// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `fmt`
// These functions are ignored (category: IgnoreBecauseExplicitAttribute): `build`

@freezed
sealed class TensorRTExecutionProvider with _$TensorRTExecutionProvider {
  const TensorRTExecutionProvider._();
  const factory TensorRTExecutionProvider.raw({
    int? deviceId,
    int? maxWorkspaceSize,
    int? minSubgraphSize,
    int? maxPartitionIterations,
    bool? fp16,
    bool? int8,
    bool? dla,
    int? dlaCore,
    String? int8CalibrationTableName,
    bool? int8UseNativeCalibrationTable,
    bool? engineCache,
    String? engineCachePath,
    bool? dumpSubgraphs,
    String? engineCachePrefix,
    bool? weightStrippedEngine,
    String? onnxModelFolderPath,
    bool? engineDecryption,
    String? engineDecryptionLibPath,
    bool? forceSequentialEngineBuild,
    bool? contextMemorySharing,
    bool? layerNormFp32Fallback,
    bool? timingCache,
    String? timingCachePath,
    bool? forceTimingCache,
    bool? detailedBuildLog,
    bool? buildHeuristics,
    bool? sparsity,
    int? builderOptimizationLevel,
    int? auxiliaryStreams,
    String? tacticSources,
    String? extraPluginLibPaths,
    String? profileMinShapes,
    String? profileMaxShapes,
    String? profileOptShapes,
    bool? cudaGraph,
    bool? dumpEpContextModel,
    String? epContextFilePath,
    int? epContextEmbedMode,
    bool? engineHwCompatible,
  }) = _TensorRTExecutionProvider;
  static Future<TensorRTExecutionProvider> default_() => RustLib.instance.api
      .crateApiExecutionProvidersTensorrtTensorRtExecutionProviderDefault();

  bool isAvailable() => RustLib.instance.api
      .crateApiExecutionProvidersTensorrtTensorRtExecutionProviderIsAvailable(
        that: this,
      );

  String name() => RustLib.instance.api
      .crateApiExecutionProvidersTensorrtTensorRtExecutionProviderName(
        that: this,
      );

  factory TensorRTExecutionProvider() => RustLib.instance.api
      .crateApiExecutionProvidersTensorrtTensorRtExecutionProviderNew();

  bool supportedByPlatform() => RustLib.instance.api
      .crateApiExecutionProvidersTensorrtTensorRtExecutionProviderSupportedByPlatform(
        that: this,
      );
}
