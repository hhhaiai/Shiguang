// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.11.1.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../../frb_generated.dart';
import '../execution_providers.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
part 'cuda.freezed.dart';

// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `clone`, `clone`, `fmt`, `fmt`, `fmt`
// These functions are ignored (category: IgnoreBecauseExplicitAttribute): `build`
// These functions are ignored (category: IgnoreBecauseNotAllowedOwner): `default`

/// The type of search done for cuDNN convolution algorithms.
enum CuDNNConvAlgorithmSearch {
  /// Expensive exhaustive benchmarking using [`cudnnFindConvolutionForwardAlgorithmEx`][exhaustive].
  /// This function will attempt all possible algorithms for `cudnnConvolutionForward` to find the fastest algorithm.
  /// Exhaustive search trades off between memory usage and speed. The first execution of a graph will be slow while
  /// possible convolution algorithms are tested.
  ///
  /// [exhaustive]: https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnFindConvolutionForwardAlgorithmEx
  exhaustive,

  /// Lightweight heuristic-based search using [`cudnnGetConvolutionForwardAlgorithm_v7`][heuristic].
  /// Heuristic search sorts available convolution algorithms by expected (based on internal heuristic) relative
  /// performance.
  ///
  /// [heuristic]: https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnGetConvolutionForwardAlgorithm_v7
  heuristic,

  /// Uses the default convolution algorithm, [`CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_PRECOMP_GEMM`][fwdalgo].
  /// The default algorithm may not have the best performance depending on specific hardware used. It's recommended to
  /// use [`Exhaustive`] or [`Heuristic`] to search for a faster algorithm instead. However, `Default` does have its
  /// uses, such as when available memory is tight.
  ///
  /// > **NOTE**: This name may be confusing as this is not the default search algorithm for the CUDA EP. The default
  /// > search algorithm is actually [`Exhaustive`].
  ///
  /// [fwdalgo]: https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionFwdAlgo_t
  /// [`Exhaustive`]: CuDNNConvAlgorithmSearch::Exhaustive
  /// [`Heuristic`]: CuDNNConvAlgorithmSearch::Heuristic
  default_,
}

enum CUDAAttentionBackend {
  flashAttention,
  efficientAttention,
  trtFusedAttention,
  cudnnFlashAttention,
  math,
  trtFlashAttention,
  trtCrossAttention,
  trtCausalAttention,
  leanAttention,
  none,
  all,
}

/// [CUDA execution provider](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html) for NVIDIA
/// CUDA-enabled GPUs.
@freezed
sealed class CUDAExecutionProvider with _$CUDAExecutionProvider {
  const CUDAExecutionProvider._();
  const factory CUDAExecutionProvider.raw({
    int? deviceId,
    int? memoryLimit,
    ArenaExtendStrategy? arenaExtendStrategy,
    CuDNNConvAlgorithmSearch? convAlgorithmSearch,
    bool? convMaxWorkspace,
    bool? conv1DPadToNc1D,
    bool? cudaGraph,
    bool? skipLayerNormStrictMode,
    bool? tf32,
    bool? preferNhwc,
    CUDAAttentionBackend? attentionBackend,
    bool? fuseConvBias,
  }) = _CUDAExecutionProvider;
  static Future<CUDAExecutionProvider> default_() => RustLib.instance.api
      .crateApiExecutionProvidersCudaCudaExecutionProviderDefault();

  bool isAvailable() => RustLib.instance.api
      .crateApiExecutionProvidersCudaCudaExecutionProviderIsAvailable(
        that: this,
      );

  String name() => RustLib.instance.api
      .crateApiExecutionProvidersCudaCudaExecutionProviderName(that: this);

  factory CUDAExecutionProvider() => RustLib.instance.api
      .crateApiExecutionProvidersCudaCudaExecutionProviderNew();

  bool supportedByPlatform() => RustLib.instance.api
      .crateApiExecutionProvidersCudaCudaExecutionProviderSupportedByPlatform(
        that: this,
      );
}
