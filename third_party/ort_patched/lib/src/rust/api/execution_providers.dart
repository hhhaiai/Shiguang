// This file is automatically generated, so please do not edit it.
// @generated by `flutter_rust_bridge`@ 2.11.1.

// ignore_for_file: invalid_use_of_internal_member, unused_import, unnecessary_import

import '../frb_generated.dart';
import 'execution_providers/coreml.dart';
import 'execution_providers/cpu.dart';
import 'execution_providers/cuda.dart';
import 'execution_providers/directml.dart';
import 'execution_providers/nnapi.dart';
import 'execution_providers/qnn.dart';
import 'execution_providers/rocm.dart';
import 'execution_providers/tensorrt.dart';
import 'execution_providers/xnnpack.dart';
import 'package:flutter_rust_bridge/flutter_rust_bridge_for_generated.dart';
import 'package:freezed_annotation/freezed_annotation.dart' hide protected;
part 'execution_providers.freezed.dart';

// These function are ignored because they are on traits that is not defined in current crate (put an empty `#[frb]` on it to unignore): `clone`, `fmt`
// These functions are ignored (category: IgnoreBecauseExplicitAttribute): `build`
// These functions are ignored (category: IgnoreBecauseNotAllowedOwner): `default`

abstract class ExecutionProviderBase {
  /// Returns `Ok(true)` if ONNX Runtime was *compiled with support* for this execution provider, and `Ok(false)`
  /// otherwise.
  ///
  /// An `Err` may be returned if a serious internal error occurs, in which case your application should probably
  /// just abort.
  ///
  /// **Note that this does not always mean the execution provider is *usable* for a specific session.** A model may
  /// use operators not supported by an execution provider, or the EP may encounter an error while attempting to load
  /// dependencies during session creation. In most cases (i.e. showing the user an error message if CUDA could not be
  /// enabled), you'll instead want to manually register this EP via [`ExecutionProvider::register`] and detect
  /// and handle any errors returned by that function.
  bool isAvailable();

  /// Returns the identifier of this execution provider used internally by ONNX Runtime.
  ///
  /// This is the same as what's used in ONNX Runtime's Python API to register this execution provider, i.e.
  /// [`TVMExecutionProvider`]'s identifier is `TvmExecutionProvider`.
  String name();

  /// Returns whether this execution provider is supported on this platform.
  ///
  /// For example, the CoreML execution provider implements this as:
  /// ```ignore
  /// impl ExecutionProvider for CoreMLExecutionProvider {
  /// 	fn supported_by_platform() -> bool {
  /// 		cfg!(target_vendor = "apple")
  /// 	}
  /// }
  /// ```
  bool supportedByPlatform();
}

/// The strategy for extending the device memory arena.
enum ArenaExtendStrategy {
  /// (Default) Subsequent extensions extend by larger amounts (multiplied by powers of two)
  nextPowerOfTwo,

  /// Memory extends by the requested amount.
  sameAsRequested,
}

@freezed
sealed class ExecutionProvider with _$ExecutionProvider {
  const ExecutionProvider._();

  const factory ExecutionProvider.coreMl(CoreMLExecutionProvider field0) =
      ExecutionProvider_CoreML;
  const factory ExecutionProvider.cpu(CPUExecutionProvider field0) =
      ExecutionProvider_CPU;
  const factory ExecutionProvider.cuda(CUDAExecutionProvider field0) =
      ExecutionProvider_CUDA;
  const factory ExecutionProvider.directMl(DirectMLExecutionProvider field0) =
      ExecutionProvider_DirectML;
  const factory ExecutionProvider.nnApi(NNAPIExecutionProvider field0) =
      ExecutionProvider_NNApi;
  const factory ExecutionProvider.qnn(QNNExecutionProvider field0) =
      ExecutionProvider_QNN;
  const factory ExecutionProvider.roCm(ROCmExecutionProvider field0) =
      ExecutionProvider_ROCm;
  const factory ExecutionProvider.tensorRt(TensorRTExecutionProvider field0) =
      ExecutionProvider_TensorRT;
  const factory ExecutionProvider.xnnpack(XNNPACKExecutionProvider field0) =
      ExecutionProvider_XNNPACK;
}
